{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 1: Third-order letter approximation model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First cell defines needed perameters such as links to files.\n",
    "A dictionary to add each text to.\n",
    "And Strings to define preamble and postable markers for removal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [\n",
    "    '/workspaces/emergingtechnologies/data/frankenstein.txt',\n",
    "    '/workspaces/emergingtechnologies/data/bookplates.txt',\n",
    "    '/workspaces/emergingtechnologies/data/spyglassmoutain.txt',\n",
    "    '/workspaces/emergingtechnologies/data/theoldhouse.txt',\n",
    "    '/workspaces/emergingtechnologies/data/windofdestiny.txt',\n",
    "]\n",
    "\n",
    "texts = {}\n",
    "\n",
    "#preamble and postamble markers\n",
    "start_marker = \" ***\"\n",
    "end_marker = \"*** END OF THE PROJECT GUTENBERG EBOOK\"\n",
    "\n",
    "startseed = \"TH\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then need to read each file, rather then doing this individually I've created a loop which adds each text to a dictionary.I've done it this way so I dont have to deal with indivdual texts and can simply loop over the dictionary when required to retrieve each text.\n",
    "\n",
    "After this I used the .find feature within the same loop, to find the markers that I've predefined and extract all text between these markers using .strip, this removes the preamble and postamble. I then add this cleaned text to the dictionary with filename as the key as this allows me to print each text separatly to check each is cleaned and for future use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read each file and remove preamble and postamble\n",
    "for file_path in files:\n",
    "    with open(file_path, 'r') as f:\n",
    "        text = f.read()\n",
    "\n",
    "        #find the start and end markers\n",
    "        start = text.find(start_marker)\n",
    "        end = text.find(end_marker)\n",
    "\n",
    "        #skip the start marker\n",
    "        start += len(start_marker)\n",
    "        #extract all text between the markers\n",
    "        text = text[start:end].strip()\n",
    "\n",
    "        #store the cleaned text in the dictionary with filename as the key\n",
    "        filename = file_path.split('/')[-1]  # Get filename from path\n",
    "        texts[filename] = text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I then create a new loop that iterates over each key-value pair in the texts dictionary. I had to add a .replace method to this to remove '/n' at it was showing up a number of times. I then define the charecters allowed in text to be fed to the model. Then changing my text to uppercase I clean the the text by removing any charecters not in the defined char set, before adding the cleaned text back to its key in the dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename, text in texts.items():\n",
    "    #remove all newlines\n",
    "    text = text.replace('\\n', ' ')    \n",
    "    text = text.upper()\n",
    "    chars = set('ABCDEFGHIJKLMNOPQRSTUVWXYZ. ')\n",
    "    #remove all characters that are not in the set of allowed characters\n",
    "    cleaned = ''.join(c for c in text if c in chars)\n",
    "    #store the cleaned text back in the dictionary\n",
    "    texts[filename] = cleaned\n",
    "\n",
    "#print(texts['theoldhouse.txt'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I then created a trigram model. Using the dictionary model and the same key value loop as before, I created a loop that iterates over the file provided in each loop, each trigram is extracted from the text. A if statement was required to remove empty values that were missed in the cleaning process. These trigrams are then added to the dictionary as a key with each occurance being counted and added to the value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = {}\n",
    "\n",
    "for filename, cleaned in texts.items():\n",
    "  #iterate over the text and count the occurrences of each trigram\n",
    "  for i in range(len(cleaned) - 2):\n",
    "    #extract the trigram\n",
    "    trigram = cleaned[i:i+3]\n",
    "    if trigram != '' and trigram != '   ':\n",
    "        #store the trigram in the model\n",
    "      model[trigram] = model.get(trigram, 0) + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is just a sorted example of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sorted(model.items(), key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 2: Third-order letter approximation generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trigram loop up dictionary for model\n",
    "trigram_dict = {}\n",
    "\n",
    "for trigram, count in model.items():\n",
    "    if len(trigram) == 3:\n",
    "        bigram = trigram[:2]\n",
    "        next_char = trigram[2]\n",
    "        if bigram not in trigram_dict:\n",
    "            trigram_dict[bigram] = {}\n",
    "        trigram_dict[bigram][next_char] = count\n",
    "\n",
    "# Manually format and print the trigram dictionary\n",
    "#for bigram, next_chars in trigram_dict.items():\n",
    "    #print(f\"Bigram '{bigram}':\")\n",
    "    #for next_char, count in next_chars.items():\n",
    "        #print(f\"  '{next_char}': {count}\")\n",
    "    #print()  # Blank line for readability between bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TH \n"
     ]
    }
   ],
   "source": [
    "#initialize the generated text with the start seed\n",
    "generated_text = startseed\n",
    "\n",
    "#get the last two characters in the generated text\n",
    "bigram = generated_text[-2:]\n",
    "\n",
    "#get possible next characters and their counts\n",
    "next_chars = list(trigram_dict[bigram].keys())\n",
    "weights = list(trigram_dict[bigram].values())\n",
    "    \n",
    "#randomly select the next character based on weights\n",
    "next_char = random.choices(next_chars, weights=weights, k=1)[0]\n",
    "    \n",
    "#next character to the generated text\n",
    "generated_text += next_char\n",
    "\n",
    "\n",
    "#print the generated text with one additional character\n",
    "print(generated_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
